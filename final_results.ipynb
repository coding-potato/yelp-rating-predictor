{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying Novel Approaches to Predict Yelp Ratings\n",
    "\n",
    "## Synopsis\n",
    "\n",
    "In our research we explore two novel methods for predicting user ratings on the domain of Yelp businesses. We provide a prospective business advertiser/marketer/researcher a detailed comparison of the differences between methods and suggest practical considerations for their usage.\n",
    "\n",
    "Keywords: Machine Learning; Collaborative Filtering; Ensemble Models; Factorization Machines\n",
    "\n",
    "#### Contributors:\n",
    "- EK Itoku | UNI: ii2155 | Email: ii2155@columbia.edu\n",
    "- Jason Kuo | UNI: jk4097 | Email: jk4097@columbia.edu\n",
    "- Sean Xu | UNI: cx2118 | Email: cx2118@columbia.edu\n",
    "\n",
    "\n",
    "#### Report Layout:\n",
    "\n",
    "* Objectives\n",
    "* Recommendation Approaches\n",
    "* Evaluation Metrics\n",
    "* Analysis of Results\n",
    "    + Comparison of Training Data Size\n",
    "    + Comparison of Hyperparameter Tuning\n",
    "* Implementation Considerations\n",
    "* Conclusions and Takeaways\n",
    "* References"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext nb_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from source.utils import plot_lines, create_quantile_bucket, rmse\n",
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.options.display.float_format = \"{:4.2f}\".format\n",
    "%matplotlib inline\n",
    "\n",
    "# Constants\n",
    "DEFAULT_SAMPLE_SIZE = 50  # 50,000 users\n",
    "QUANTILES = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\n",
    "    \"user_id\",\n",
    "    \"business_id\",\n",
    "    \"review_stars\",\n",
    "    \"user_average_stars\",\n",
    "    \"user_review_count\",\n",
    "    \"user_elite\",\n",
    "    \"user_fans\",\n",
    "    \"business_stars\",\n",
    "    \"business_review_count\",\n",
    "]\n",
    "truth = pd.read_csv(\"data/feature.csv\", usecols=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# [fn for fn in os.listdir(\"result\") if fn.endswith(\"_pred.pkl\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model_result_files = [\n",
    "    \"baseline_pred.pkl\",\n",
    "    \"knnwithmeans_pred.pkl\",\n",
    "    \"svd_pred.pkl\",\n",
    "    \"coclustering_pred.pkl\",\n",
    "    \"knnbasic_pred.pkl\",\n",
    "    \"ensemble_pred.pkl\",\n",
    "    \"fm_pred.pkl\",\n",
    "]\n",
    "preds = []\n",
    "\n",
    "for fn in model_result_files:\n",
    "    pred = pd.read_pickle(f\"result/{fn}\")\n",
    "    pred = pred.merge(truth, on=[\"user_id\", \"business_id\"], how=\"inner\")\n",
    "\n",
    "    pred[\"squared_error\"] = (pred.review_stars - pred.y_pred) ** 2\n",
    "    pred[\"absolute_error\"] = (pred.review_stars - pred.y_pred).abs()\n",
    "\n",
    "    preds.append([fn.split(\"_\")[0], pred])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives\n",
    "\n",
    "In this study we aim to predict the rating of the last business a Yelp user visits. A rating is on the scale of 1 - 5 with 5 representing great. For marketing companies, this can be invaluable in identifying potential users who will like a targeted business and only focus advertising to those users with high predicted ratings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Metrics\n",
    "\n",
    "To achieve our objective, we used two different evaluation schemes:\n",
    "\n",
    "\n",
    "#### - Root Mean Squared Error (Primary Benchmark)\n",
    "\n",
    "We use the root mean squared error benchmark (RMSE) to measure the deviation of our predicted rating from the true rating in our testing set. A lower result is better signaling less prediction error.\n",
    "\n",
    "\n",
    "#### - Mean Absolute Error (Secondary Benchmark)\n",
    "\n",
    "RMSE penalizes the larger deviations from the true rating more than similarly spaced apart smaller deviations when the total amount of deviation is the same. Mean Absolute Error (MAE) measures all deviations similarly. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recommendation Approaches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Baseline model (Biased Model)\n",
    "<img src=\"image/baseline1.png\" alt=\"drawing\" width=\"200\"/>\n",
    "Where we adjust the mean rating of all users and all items by the observed deviations of user u and item i.\n",
    "\n",
    "In order to avoid overfitting, we add regularizations by penalizing the magnitudes of the parameters.\n",
    "<img src=\"image/baseline2.png\" alt=\"drawing\" width=\"400\"/>\n",
    "\n",
    "In Surprise implementation, for easier calculation, it decouples the calculation of b_u and b_i. For b_i\n",
    "<img src=\"image/baseline3.png\" alt=\"drawing\" width=\"300\"/>\n",
    "\n",
    "For b_u\n",
    "<img src=\"image/baseline4.png\" alt=\"drawing\" width=\"300\"/>\n",
    "\n",
    "And Surprise provides two algorithms to calculate the parameters: Baselines can be estimated in two different ways:\n",
    "Stochastic Gradient Descent (SGD)\n",
    "Alternating Least Squares (ALS)\n",
    "\n",
    "We run a GridSearch for both algorithms and the accuracy matrix we use is:\n",
    "- Primary: RMSE\n",
    "- Secondary: MAE\n",
    "\n",
    "Results:\n",
    "\n",
    "\n",
    "\n",
    "Algorithm | Model with least RMSE | RMSE | Model with least MAE | MAE\n",
    "----------|-----------------------|------|----------------------|----\n",
    "ALS|'n_epochs': 30, 'reg_u': 10, 'reg_i': 10|1.15|'n_epochs': 30, 'reg_u': 10, 'reg_i': 10 |0.92\n",
    "SGD|'n_epochs': 30, 'reg': 0.1, 'learning_rate': 0.005|1.15|'n_epochs': 30, 'reg': 0.01, 'learning_rate': 0.01|0.90\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Individual and Ensemble Methods\n",
    "\n",
    "#### Individual models\n",
    "We considered several models individually and then ensembling them including:\n",
    "- KNN\n",
    "- KNN(Basic and With_Means)\n",
    "- SVD\n",
    "- baselineonly\n",
    "- co-colustering\n",
    "\n",
    "#### - KNN\n",
    "The idea is to use similar users or items to predict the rating of given user and item. \n",
    "\n",
    "<img src=\"image/knn1.png\" alt=\"drawing\" width=\"300\"/>\n",
    "<img src=\"image/knn2.png\" alt=\"drawing\" width=\"300\"/>\n",
    "\n",
    "There are several ways to calculate the similarities including cosine, pearson and msd.\n",
    "Results:\n",
    "\n",
    "\n",
    "Algorithm|Model with least RMSE|RMSE|Model with least MAE|MAE\n",
    "---------|---------------------|----|--------------------|---\n",
    "KNNBasic|‘similarity_method’: cosine, 'k': 40|1.50|‘similarity_method’: msd, 'k': 20|1.12\n",
    "KNNwithMean|‘similarity_method’: cosine, 'k': 40|1.39|‘similarity_method’: cosine, 'k': 40|1.05\n",
    "\n",
    "#### - SVD\n",
    "A matrix factorization method which is popularized by Simon Funk during the Netflix Prize. When baselines are not used, this is equivalent to Probabilistic Matrix Factorization. \n",
    "\n",
    "Algorithm|Model with least RMSE|RMSE|Model with least MAE|MAE\n",
    "---------|---------------------|----|--------------------|---\n",
    "SVD|'n_factors': 50, 'lr_all': 0.005, 'reg_all': 0.1|1.13|'n_factors': 50, 'lr_all': 0.01, 'reg_all': 0.1|0.89\n",
    "\n",
    "\n",
    "#### - Co-Clustering\n",
    "\n",
    "Cluster assignments are done by basic techniques like kmeans.\n",
    "\n",
    "<img src=\"image/cocluster.png\" alt=\"drawing\" width=\"600\"/>\n",
    "\n",
    "#### Ensemble\n",
    "\n",
    "#### - Basic Ensemble\n",
    "The idea of ensemble model is to stack a set of basic recommendation models and use the weighted sum of the predictions as the new prediction which will  remove the flaws in individual implementation.\n",
    "- Averaging\n",
    "- Weighted Average (Train weights with linear regression and ElasticNet regression)\n",
    "\n",
    "Steps:\n",
    "1. Tune the hyperparameter of base models including:\n",
    "2. Train base models using the tuned hyperparameters\n",
    "3. Run regression to learn the weights or simply user average\n",
    "4. Stack models together with weights (average or trained weights)\n",
    "\n",
    "Results:\n",
    "\n",
    "\n",
    "Model | RMSE\n",
    "------|-----\n",
    "Base Models|1.13 - 1.33\n",
    "Ensemble with average weights|1.32\n",
    "Ensemble with weights learned from linear regression|1.32\n",
    "Ensemble with weights learned from ElasticNet|1.39\n",
    "\n",
    "Model | MAE\n",
    "------|----\n",
    "Base Models|0.9 - 1\n",
    "Ensemble with average weights|1.05\n",
    "Ensemble with weights learned from linear regression|1.03\n",
    "Ensemble with weights learned from ElasticNet|1.11\n",
    "\n",
    "\n",
    "#### - Advanced Ensemble Techniques\n",
    "- Stacking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Factorization Machines\n",
    "\n",
    "Factorization Machines are a state of the art solution to recommendation problems. In theory, FMs should produce better results than MF due to interaction terms but in practice it might not necessary be the case. If side information is omitted, then FMs become the same as the MF model.\n",
    "\n",
    "FMs are similar to collective approaches allowing for multiple relationships between entities but differ in:\n",
    "- FMs use a clever feature representation to cast factorization as a regression, classification, or ranking problem\n",
    "- In addition to relations between entities, FMs allow for interaction terms for items within a single entity type\n",
    "- FMs can be defined such that they act like, or mimic, other techniques like SVD++\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis of Results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Baseline (Most Popular 5 Movies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Update for yelp project\n",
    "\n",
    "In our baseline method we achieved a RMSE of 1.006 and precision of 0.0337 on the test data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Neighborhood-Based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# with open(path_nb_result, 'rb') as f:\n",
    "#     nb_result = pickle.load(f)\n",
    "\n",
    "# test_acc = nb_result.loc[nb_result.sample_size == DEFAULT_SAMPLE_SIZE, ['rmse_test', 'top_k_precision_test']].values[0]\n",
    "\n",
    "# print(\"In our neighborhood-based method we achieved a RMSE of {0} and precision of {1} on the test data.\"\n",
    "#       .format(round(test_acc[0],4), round(test_acc[1],4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model-Based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(path_als_result, 'rb') as f:\n",
    "#     als_result = pickle.load(f)\n",
    "    \n",
    "# test_acc = als_result.loc[als_result.sample_size == DEFAULT_SAMPLE_SIZE, ['rmse_test', 'top_k_precision_test']].values[0]\n",
    "\n",
    "# print(\"In our model-based method we achieved a RMSE of {0} and precision of {1} on the test data.\"\n",
    "#       .format(round(test_acc[0],4), round(test_acc[1],4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Update for yelp project\n",
    "\n",
    "Surprisingly, our baseline popularity method did resonably well in test RMSE however it predictably did poor on the precision side. The neighborhood model improved RMSE and notably precision vs. the baseline. Finally, our model-based method performed the best with RMSE and slightly worse on precision vs. the NB method on the test dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do your models work equally well for all users?\n",
    "\n",
    "We will evaluate models from two different angles\n",
    "##### 1. In terms of number of users\n",
    "The more users review restaurants, the better our predictions perform. This is intuitive as there are more samples models to learn, we can train models better.\n",
    "\n",
    "\n",
    "##### 2. In terms of number of elite status\n",
    "Our experiments show that our models perform better for elite users. For example, MAE is 0.78 for elite users whereas 1.03 for non-elite users. We think this is because there are more samples for elite users. Another possibility is that  there might be some spam users or malicious business accounts that rate restaurants in an unusual manner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baseline\n",
      "                         count  mean  std  min  25%  50%  75%  max\n",
      "user_review_count_bin                                             \n",
      "(4.999, 7.0]          35329.00  1.12 0.81 0.00 0.51 0.95 1.59 4.00\n",
      "(7.0, 9.0]            24570.00  1.10 0.82 0.00 0.46 0.92 1.56 4.00\n",
      "(9.0, 11.0]           20224.00  1.07 0.80 0.00 0.45 0.90 1.52 4.00\n",
      "(11.0, 14.0]          23186.00  1.04 0.79 0.00 0.43 0.87 1.49 4.00\n",
      "(14.0, 18.0]          22003.00  1.02 0.79 0.00 0.42 0.86 1.45 4.00\n",
      "(18.0, 25.0]          24238.00  1.01 0.79 0.00 0.39 0.84 1.45 4.00\n",
      "(25.0, 38.0]          23846.00  0.98 0.78 0.00 0.38 0.81 1.40 4.00\n",
      "(38.0, 68.0]          24415.00  0.93 0.75 0.00 0.36 0.77 1.31 4.00\n",
      "(68.0, 161.0]         24665.00  0.88 0.70 0.00 0.35 0.72 1.23 4.00\n",
      "(161.0, 13278.0]      24647.00  0.79 0.63 0.00 0.31 0.66 1.10 4.00\n",
      "\n",
      "\n",
      "knnwithmeans\n",
      "                         count  mean  std  min  25%  50%  75%  max\n",
      "user_review_count_bin                                             \n",
      "(4.999, 7.0]          35329.00  1.18 1.02 0.00 0.30 1.04 1.78 4.00\n",
      "(7.0, 9.0]            24570.00  1.14 1.01 0.00 0.30 1.00 1.72 4.00\n",
      "(9.0, 11.0]           20224.00  1.10 0.97 0.00 0.29 0.93 1.61 4.00\n",
      "(11.0, 14.0]          23186.00  1.08 0.95 0.00 0.29 0.89 1.58 4.00\n",
      "(14.0, 18.0]          22003.00  1.05 0.92 0.00 0.30 0.85 1.53 4.00\n",
      "(18.0, 25.0]          24238.00  1.04 0.90 0.00 0.31 0.84 1.51 4.00\n",
      "(25.0, 38.0]          23846.00  1.00 0.86 0.00 0.32 0.82 1.44 4.00\n",
      "(38.0, 68.0]          24415.00  0.96 0.82 0.00 0.32 0.78 1.35 4.00\n",
      "(68.0, 161.0]         24665.00  0.91 0.77 0.00 0.31 0.74 1.26 4.00\n",
      "(161.0, 13278.0]      24647.00  0.82 0.69 0.00 0.30 0.68 1.16 4.00\n",
      "\n",
      "\n",
      "svd\n",
      "                         count  mean  std  min  25%  50%  75%  max\n",
      "user_review_count_bin                                             \n",
      "(4.999, 7.0]          35329.00  1.14 0.78 0.00 0.55 0.97 1.56 4.00\n",
      "(7.0, 9.0]            24570.00  1.12 0.79 0.00 0.52 0.95 1.54 4.00\n",
      "(9.0, 11.0]           20224.00  1.08 0.77 0.00 0.50 0.91 1.48 4.00\n",
      "(11.0, 14.0]          23186.00  1.06 0.77 0.00 0.48 0.89 1.47 4.00\n",
      "(14.0, 18.0]          22003.00  1.04 0.77 0.00 0.46 0.87 1.43 4.00\n",
      "(18.0, 25.0]          24238.00  1.01 0.77 0.00 0.43 0.84 1.42 4.00\n",
      "(25.0, 38.0]          23846.00  0.98 0.76 0.00 0.41 0.81 1.36 4.00\n",
      "(38.0, 68.0]          24415.00  0.93 0.73 0.00 0.38 0.77 1.28 4.00\n",
      "(68.0, 161.0]         24665.00  0.87 0.68 0.00 0.36 0.73 1.20 4.00\n",
      "(161.0, 13278.0]      24647.00  0.78 0.62 0.00 0.31 0.66 1.08 4.00\n",
      "\n",
      "\n",
      "coclustering\n",
      "                         count  mean  std  min  25%  50%  75%  max\n",
      "user_review_count_bin                                             \n",
      "(4.999, 7.0]          35329.00  1.18 1.08 0.00 0.20 1.01 1.84 4.00\n",
      "(7.0, 9.0]            24570.00  1.15 1.05 0.00 0.21 1.00 1.76 4.00\n",
      "(9.0, 11.0]           20224.00  1.10 1.02 0.00 0.22 0.92 1.66 4.00\n",
      "(11.0, 14.0]          23186.00  1.08 0.99 0.00 0.24 0.89 1.62 4.00\n",
      "(14.0, 18.0]          22003.00  1.05 0.95 0.00 0.26 0.85 1.57 4.00\n",
      "(18.0, 25.0]          24238.00  1.03 0.92 0.00 0.28 0.84 1.53 4.00\n",
      "(25.0, 38.0]          23846.00  1.00 0.89 0.00 0.29 0.81 1.47 4.00\n",
      "(38.0, 68.0]          24415.00  0.96 0.84 0.00 0.30 0.79 1.39 4.00\n",
      "(68.0, 161.0]         24665.00  0.92 0.79 0.00 0.31 0.75 1.30 4.00\n",
      "(161.0, 13278.0]      24647.00  0.85 0.71 0.00 0.30 0.70 1.19 4.00\n",
      "\n",
      "\n",
      "knnbasic\n",
      "                         count  mean  std  min  25%  50%  75%  max\n",
      "user_review_count_bin                                             \n",
      "(4.999, 7.0]          35329.00  1.24 1.13 0.00 0.16 1.16 1.98 4.00\n",
      "(7.0, 9.0]            24570.00  1.23 1.11 0.00 0.24 1.00 1.95 4.00\n",
      "(9.0, 11.0]           20224.00  1.17 1.07 0.00 0.21 1.00 1.84 4.00\n",
      "(11.0, 14.0]          23186.00  1.16 1.05 0.00 0.28 1.00 1.77 4.00\n",
      "(14.0, 18.0]          22003.00  1.13 1.00 0.00 0.33 1.00 1.69 4.00\n",
      "(18.0, 25.0]          24238.00  1.12 0.97 0.00 0.34 0.99 1.66 4.00\n",
      "(25.0, 38.0]          23846.00  1.09 0.92 0.00 0.38 0.97 1.52 4.00\n",
      "(38.0, 68.0]          24415.00  1.03 0.86 0.00 0.36 0.91 1.45 4.00\n",
      "(68.0, 161.0]         24665.00  0.97 0.81 0.00 0.34 0.85 1.33 4.00\n",
      "(161.0, 13278.0]      24647.00  0.90 0.74 0.00 0.33 0.79 1.22 4.00\n",
      "\n",
      "\n",
      "ensemble\n",
      "                         count  mean  std  min  25%  50%  75%  max\n",
      "user_review_count_bin                                             \n",
      "(4.999, 7.0]          35329.00  1.17 0.84 0.00 0.50 1.00 1.50 4.00\n",
      "(7.0, 9.0]            24570.00  1.14 0.86 0.00 0.50 1.00 1.50 4.00\n",
      "(9.0, 11.0]           20224.00  1.10 0.84 0.00 0.50 1.00 1.50 4.00\n",
      "(11.0, 14.0]          23186.00  1.08 0.84 0.00 0.50 1.00 1.50 4.00\n",
      "(14.0, 18.0]          22003.00  1.05 0.83 0.00 0.50 1.00 1.50 4.00\n",
      "(18.0, 25.0]          24238.00  1.03 0.83 0.00 0.50 1.00 1.50 4.00\n",
      "(25.0, 38.0]          23846.00  0.99 0.82 0.00 0.50 1.00 1.50 4.00\n",
      "(38.0, 68.0]          24415.00  0.94 0.79 0.00 0.50 1.00 1.50 4.00\n",
      "(68.0, 161.0]         24665.00  0.88 0.74 0.00 0.50 0.50 1.00 4.00\n",
      "(161.0, 13278.0]      24647.00  0.80 0.68 0.00 0.50 0.50 1.00 4.00\n",
      "\n",
      "\n",
      "fm\n",
      "                         count  mean  std  min  25%  50%  75%  max\n",
      "user_review_count_bin                                             \n",
      "(4.999, 7.0]          35329.00  1.05 0.84 0.00 0.38 0.84 1.55 5.31\n",
      "(7.0, 9.0]            24570.00  1.09 0.75 0.00 0.49 0.96 1.55 4.33\n",
      "(9.0, 11.0]           20224.00  1.09 0.74 0.00 0.51 0.96 1.53 4.44\n",
      "(11.0, 14.0]          23186.00  1.10 0.76 0.00 0.52 0.95 1.52 4.41\n",
      "(14.0, 18.0]          22003.00  1.10 0.77 0.00 0.53 0.94 1.49 4.03\n",
      "(18.0, 25.0]          24238.00  1.11 0.77 0.00 0.56 0.96 1.45 4.07\n",
      "(25.0, 38.0]          23846.00  1.09 0.75 0.00 0.63 0.99 1.36 3.67\n",
      "(38.0, 68.0]          24415.00  1.06 0.71 0.00 0.55 1.05 1.31 3.74\n",
      "(68.0, 161.0]         24665.00  0.99 0.68 0.00 0.35 1.04 1.30 3.51\n",
      "(161.0, 13278.0]      24647.00  0.89 0.65 0.00 0.27 0.83 1.25 3.37\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 1. In terms of number of users\n",
    "for nm, pred in preds:\n",
    "    pred[\"user_review_count_bin\"] = pd.qcut(pred.user_review_count, 10)\n",
    "    desc = pred.groupby(\"user_review_count_bin\").absolute_error.describe()\n",
    "    print(nm)\n",
    "    print(desc)\n",
    "    print()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baseline\n",
      "               count  mean  std  min  25%  50%  75%  max\n",
      "user_elite                                              \n",
      "False      213281.00  1.03 0.79 0.00 0.42 0.86 1.47 4.00\n",
      "True        33842.00  0.78 0.63 0.00 0.31 0.64 1.09 4.00\n",
      "\n",
      "\n",
      "knnwithmeans\n",
      "               count  mean  std  min  25%  50%  75%  max\n",
      "user_elite                                              \n",
      "False      213281.00  1.07 0.93 0.00 0.31 0.88 1.54 4.00\n",
      "True        33842.00  0.81 0.69 0.00 0.29 0.66 1.15 4.00\n",
      "\n",
      "\n",
      "svd\n",
      "               count  mean  std  min  25%  50%  75%  max\n",
      "user_elite                                              \n",
      "False      213281.00  1.04 0.77 0.00 0.46 0.87 1.44 4.00\n",
      "True        33842.00  0.77 0.62 0.00 0.31 0.65 1.07 4.00\n",
      "\n",
      "\n",
      "coclustering\n",
      "               count  mean  std  min  25%  50%  75%  max\n",
      "user_elite                                              \n",
      "False      213281.00  1.07 0.97 0.00 0.26 0.88 1.57 4.00\n",
      "True        33842.00  0.83 0.71 0.00 0.29 0.68 1.16 4.00\n",
      "\n",
      "\n",
      "knnbasic\n",
      "               count  mean  std  min  25%  50%  75%  max\n",
      "user_elite                                              \n",
      "False      213281.00  1.14 1.01 0.00 0.33 1.00 1.69 4.00\n",
      "True        33842.00  0.88 0.74 0.00 0.32 0.76 1.17 4.00\n",
      "\n",
      "\n",
      "ensemble\n",
      "               count  mean  std  min  25%  50%  75%  max\n",
      "user_elite                                              \n",
      "False      213281.00  1.06 0.83 0.00 0.50 1.00 1.50 4.00\n",
      "True        33842.00  0.79 0.68 0.00 0.50 0.50 1.00 4.00\n",
      "\n",
      "\n",
      "fm\n",
      "               count  mean  std  min  25%  50%  75%  max\n",
      "user_elite                                              \n",
      "False      213281.00  1.09 0.76 0.00 0.49 0.98 1.46 5.31\n",
      "True        33842.00  0.86 0.65 0.00 0.23 0.87 1.18 3.67\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 2. In terms of number of elite status\n",
    "\n",
    "for nm, pred in preds:\n",
    "    pred.user_elite = pred.user_elite > 0\n",
    "    desc = pred.groupby(\"user_elite\").absolute_error.describe()\n",
    "    print(nm)\n",
    "    print(desc)\n",
    "    print()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do your models work equally well for all restaurants?\n",
    "\n",
    "Our models perform better for the restaurants that are popular with more reviews. Similar to the user analysis above, models perform better if there are more data to learn patterns on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baseline\n",
      "                             count  mean  std  min  25%  50%  75%  max\n",
      "business_review_count_bin                                             \n",
      "(49.999, 84.0]            25035.00  1.10 0.80 0.00 0.47 0.96 1.59 4.00\n",
      "(84.0, 125.0]             24420.00  1.05 0.78 0.00 0.44 0.89 1.50 4.00\n",
      "(125.0, 173.0]            25025.00  1.06 0.78 0.00 0.44 0.90 1.52 4.00\n",
      "(173.0, 236.0]            24782.00  1.03 0.78 0.00 0.43 0.86 1.47 4.00\n",
      "(236.0, 313.0]            24431.00  1.02 0.79 0.00 0.41 0.84 1.45 4.00\n",
      "(313.0, 413.0]            24706.00  1.00 0.78 0.00 0.41 0.83 1.40 4.00\n",
      "(413.0, 555.0]            24662.00  0.98 0.77 0.00 0.39 0.80 1.37 4.00\n",
      "(555.0, 851.0]            24650.00  0.97 0.77 0.00 0.38 0.78 1.35 4.00\n",
      "(851.0, 1476.0]           24765.00  0.90 0.75 0.00 0.36 0.72 1.22 4.00\n",
      "(1476.0, 8348.0]          24647.00  0.87 0.71 0.00 0.34 0.72 1.19 4.00\n",
      "\n",
      "\n",
      "knnwithmeans\n",
      "                             count  mean  std  min  25%  50%  75%  max\n",
      "business_review_count_bin                                             \n",
      "(49.999, 84.0]            25035.00  1.14 0.95 0.00 0.36 0.96 1.69 4.00\n",
      "(84.0, 125.0]             24420.00  1.08 0.92 0.00 0.34 0.89 1.56 4.00\n",
      "(125.0, 173.0]            25025.00  1.09 0.93 0.00 0.33 0.91 1.60 4.00\n",
      "(173.0, 236.0]            24782.00  1.06 0.92 0.00 0.32 0.86 1.52 4.00\n",
      "(236.0, 313.0]            24431.00  1.05 0.92 0.00 0.30 0.85 1.50 4.00\n",
      "(313.0, 413.0]            24706.00  1.03 0.91 0.00 0.30 0.84 1.44 4.00\n",
      "(413.0, 555.0]            24662.00  1.01 0.90 0.00 0.29 0.83 1.43 4.00\n",
      "(555.0, 851.0]            24650.00  1.00 0.89 0.00 0.30 0.82 1.39 4.00\n",
      "(851.0, 1476.0]           24765.00  0.94 0.86 0.00 0.26 0.75 1.27 4.00\n",
      "(1476.0, 8348.0]          24647.00  0.92 0.81 0.00 0.27 0.75 1.26 4.00\n",
      "\n",
      "\n",
      "svd\n",
      "                             count  mean  std  min  25%  50%  75%  max\n",
      "business_review_count_bin                                             \n",
      "(49.999, 84.0]            25035.00  1.11 0.77 0.00 0.50 0.97 1.59 4.00\n",
      "(84.0, 125.0]             24420.00  1.06 0.77 0.00 0.47 0.90 1.49 3.98\n",
      "(125.0, 173.0]            25025.00  1.06 0.76 0.00 0.47 0.91 1.49 4.00\n",
      "(173.0, 236.0]            24782.00  1.03 0.76 0.00 0.45 0.88 1.44 4.00\n",
      "(236.0, 313.0]            24431.00  1.03 0.77 0.00 0.45 0.86 1.42 4.00\n",
      "(313.0, 413.0]            24706.00  1.01 0.76 0.00 0.44 0.84 1.36 4.00\n",
      "(413.0, 555.0]            24662.00  0.99 0.75 0.00 0.43 0.82 1.34 4.00\n",
      "(555.0, 851.0]            24650.00  0.97 0.75 0.00 0.42 0.81 1.30 4.00\n",
      "(851.0, 1476.0]           24765.00  0.91 0.72 0.00 0.39 0.74 1.19 4.00\n",
      "(1476.0, 8348.0]          24647.00  0.87 0.69 0.00 0.35 0.73 1.16 4.00\n",
      "\n",
      "\n",
      "coclustering\n",
      "                             count  mean  std  min  25%  50%  75%  max\n",
      "business_review_count_bin                                             \n",
      "(49.999, 84.0]            25035.00  1.13 0.99 0.00 0.31 0.95 1.72 4.00\n",
      "(84.0, 125.0]             24420.00  1.07 0.95 0.00 0.29 0.89 1.57 4.00\n",
      "(125.0, 173.0]            25025.00  1.09 0.97 0.00 0.28 0.90 1.61 4.00\n",
      "(173.0, 236.0]            24782.00  1.06 0.96 0.00 0.27 0.87 1.56 4.00\n",
      "(236.0, 313.0]            24431.00  1.05 0.96 0.00 0.26 0.86 1.55 4.00\n",
      "(313.0, 413.0]            24706.00  1.04 0.95 0.00 0.25 0.84 1.48 4.00\n",
      "(413.0, 555.0]            24662.00  1.02 0.94 0.00 0.25 0.83 1.47 4.00\n",
      "(555.0, 851.0]            24650.00  1.01 0.93 0.00 0.26 0.83 1.45 4.00\n",
      "(851.0, 1476.0]           24765.00  0.95 0.90 0.00 0.22 0.76 1.31 4.00\n",
      "(1476.0, 8348.0]          24647.00  0.94 0.85 0.00 0.26 0.78 1.31 4.00\n",
      "\n",
      "\n",
      "knnbasic\n",
      "                             count  mean  std  min  25%  50%  75%  max\n",
      "business_review_count_bin                                             \n",
      "(49.999, 84.0]            25035.00  1.25 1.07 0.00 0.34 1.00 1.96 4.00\n",
      "(84.0, 125.0]             24420.00  1.17 1.02 0.00 0.33 1.00 1.75 4.00\n",
      "(125.0, 173.0]            25025.00  1.17 1.03 0.00 0.33 1.00 1.76 4.00\n",
      "(173.0, 236.0]            24782.00  1.13 1.01 0.00 0.32 1.00 1.66 4.00\n",
      "(236.0, 313.0]            24431.00  1.12 1.00 0.00 0.31 1.00 1.63 4.00\n",
      "(313.0, 413.0]            24706.00  1.09 0.98 0.00 0.30 1.00 1.51 4.00\n",
      "(413.0, 555.0]            24662.00  1.09 0.97 0.00 0.32 1.00 1.52 4.00\n",
      "(555.0, 851.0]            24650.00  1.06 0.95 0.00 0.32 0.98 1.49 4.00\n",
      "(851.0, 1476.0]           24765.00  1.02 0.91 0.00 0.32 0.92 1.40 4.00\n",
      "(1476.0, 8348.0]          24647.00  1.00 0.87 0.00 0.33 0.93 1.37 4.00\n",
      "\n",
      "\n",
      "ensemble\n",
      "                             count  mean  std  min  25%  50%  75%  max\n",
      "business_review_count_bin                                             \n",
      "(49.999, 84.0]            25035.00  1.14 0.83 0.00 0.50 1.00 1.50 4.00\n",
      "(84.0, 125.0]             24420.00  1.08 0.82 0.00 0.50 1.00 1.50 4.00\n",
      "(125.0, 173.0]            25025.00  1.08 0.82 0.00 0.50 1.00 1.50 4.00\n",
      "(173.0, 236.0]            24782.00  1.06 0.82 0.00 0.50 1.00 1.50 4.00\n",
      "(236.0, 313.0]            24431.00  1.05 0.83 0.00 0.50 1.00 1.50 4.00\n",
      "(313.0, 413.0]            24706.00  1.02 0.82 0.00 0.50 1.00 1.50 4.00\n",
      "(413.0, 555.0]            24662.00  1.00 0.82 0.00 0.50 1.00 1.50 4.00\n",
      "(555.0, 851.0]            24650.00  0.99 0.81 0.00 0.50 1.00 1.50 4.00\n",
      "(851.0, 1476.0]           24765.00  0.92 0.80 0.00 0.50 1.00 1.00 4.00\n",
      "(1476.0, 8348.0]          24647.00  0.88 0.76 0.00 0.50 0.50 1.00 4.00\n",
      "\n",
      "\n",
      "fm\n",
      "                             count  mean  std  min  25%  50%  75%  max\n",
      "business_review_count_bin                                             \n",
      "(49.999, 84.0]            25035.00  1.17 0.81 0.00 0.54 1.05 1.65 4.97\n",
      "(84.0, 125.0]             24420.00  1.11 0.79 0.00 0.49 0.99 1.52 5.24\n",
      "(125.0, 173.0]            25025.00  1.10 0.77 0.00 0.50 0.99 1.51 5.03\n",
      "(173.0, 236.0]            24782.00  1.08 0.77 0.00 0.47 0.97 1.45 4.24\n",
      "(236.0, 313.0]            24431.00  1.07 0.77 0.00 0.48 0.97 1.42 5.31\n",
      "(313.0, 413.0]            24706.00  1.04 0.74 0.00 0.45 0.94 1.38 4.32\n",
      "(413.0, 555.0]            24662.00  1.03 0.74 0.00 0.46 0.94 1.36 4.70\n",
      "(555.0, 851.0]            24650.00  1.01 0.73 0.00 0.42 0.93 1.33 4.20\n",
      "(851.0, 1476.0]           24765.00  0.98 0.69 0.00 0.40 0.93 1.29 4.33\n",
      "(1476.0, 8348.0]          24647.00  0.95 0.67 0.00 0.36 0.91 1.29 4.44\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for nm, pred in preds:\n",
    "    pred[\"business_review_count_bin\"] = pd.qcut(pred.business_review_count, 10)\n",
    "    desc = pred.groupby(\"business_review_count_bin\").absolute_error.describe()\n",
    "    print(nm)\n",
    "    print(desc)\n",
    "    print()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Think carefully about a business or technical framework to segment your data for users, items, or more, and test accuracy separately for these segments\n",
    "\n",
    "TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison of Hyper Parameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Neighborhood-Based: Increasing K-Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(path_nb_100k_hyper_rmse, 'rb') as f:\n",
    "#     nb_100k_hyper_rmse = pickle.load(f)\n",
    "    \n",
    "# with open(path_nb_100k_hyper_precision, 'rb') as f:\n",
    "#     nb_100k_hyper_precision = pickle.load(f)\n",
    "\n",
    "# k = nb_100k_hyper_rmse[1].values\n",
    "# rmse = nb_100k_hyper_rmse[2].values\n",
    "# precision = nb_100k_hyper_precision[2].values\n",
    "    \n",
    "# plot_lines(k, rmse, 'Neighborhood-Based RMSE vs. K-Neighbors', 'K', 'RMSE')\n",
    "# plot_lines(k, precision, 'Neighborhood-Based Precision vs. K-Neighbors', 'K', 'Precision')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# min_rmse_idx = np.argmin(rmse)\n",
    "# best_k = k[min_rmse_idx]\n",
    "# lowest_RMSE = rmse[min_rmse_idx]\n",
    "# print(\"K of {0} looks to be the result with the lowest RMSE ({1}) on the test data.\"\n",
    "#       .format(round(best_k,4), round(lowest_RMSE,4)))\n",
    "\n",
    "# max_precision_idx = np.argmax(precision)\n",
    "# best_k = k[max_precision_idx]\n",
    "# highest_precision = precision[max_precision_idx]\n",
    "# print(\"K of {0} looks to be the result with the highest precision ({1}) on the test data.\"\n",
    "#       .format(round(best_k,4), round(highest_precision,4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Update for yelp project\n",
    "\n",
    "From the data, we can see the hyperparameter K for the number of neighbors to calculate similarity with can be tuned to improved RMSE however at a cost of precision. It appears that using a smaller clique of peers improves the likelihood of finding a desirable top 5 movie however it comes with a tradeoff of being less accurate in predicting its exact rating. Perhaps favoring precision in this tradeoff is resonable for a business to optimize if they are looking to maximize movie visits and worry less about how people thought of them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model-Based: Increasing Regularization Parameter (λ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Update for yelp project\n",
    "\n",
    "# with open(path_als_100k_hyper_rmse, 'rb') as f:\n",
    "#     als_100k_hyper_rmse = pickle.load(f)\n",
    "\n",
    "# lam_cv = als_100k_hyper_rmse[1].values\n",
    "# rmse_cv = als_100k_hyper_rmse[2].values\n",
    "\n",
    "# param_size = int(len(lam_cv)/CV_K_FOLDS)\n",
    "# lam = lam_cv[:param_size]\n",
    "# rmse_per_kfold = np.array_split(rmse_cv, CV_K_FOLDS)\n",
    "# rmse = np.mean(rmse_per_kfold, axis=0)\n",
    "\n",
    "# plot_lines(lam, rmse, 'Model-Based RMSE vs. Regularization Parameter', 'λ', 'RMSE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Update for yelp project\n",
    "\n",
    "# min_rmse_idx = np.argmin(rmse)\n",
    "# best_lamda = lam[min_rmse_idx]\n",
    "# lowest_RMSE = rmse[min_rmse_idx]\n",
    "# print(\"Lambda of {0} looks to be the result with the lowest RMSE ({1}) on the test data.\"\n",
    "#       .format(round(best_lamda,4), round(lowest_RMSE,4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Update for yelp project\n",
    "\n",
    "As we tweaked the regularization parameter lambda, we were able to find an optimal level to minimize RMSE. This lambda is used for the Alternating Least Squares algorithm to generalize the model better through introducing penalty to latent factor weights.\n",
    "\n",
    "In our final model we tuned additional hyperparameters for max iterations the model should run and rank (dimensionality of latent factors) through cross validation however due to model package limitations were unable to extract the outputs in an efficient manner. Similarly, the precision metric was not easily exposed on a hyperparameter tuning level of which we omit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation Considerations\n",
    "\n",
    "For any business looking to employ one of these methods into real-world use, they should consider the following:\n",
    "\n",
    "#### Cold Start\n",
    "\n",
    "TODO: Update for yelp project\n",
    "\n",
    "In the case the business has no existing user-item recommendation data, the company can ensure a randomized selection of movie predictions in order to generate a dataset with a resonable selection of movies to recommend. As we seen in data scaling, introducing too wide of a selection of movies can make prediction accuracy suffer due to the sparcity of ratings in the neighborhood-based method but can be partially addressed in the model-based matrix factorization method.\n",
    "\n",
    "#### New Users\n",
    "\n",
    "TODO: Update for yelp project\n",
    "\n",
    "With no existing data, it is question on how to provide an appropriate recommendation for new users. We suggest an employing a popularity-based approach (i.e. suggesting the top-k most popular items) as it has been shown to provide a decent performance vs. the methods incorporating additional user data. The business can continue to approach until the user has accumulated a sufficient number movie interactions at which the predictions can be reliably estimated (a business rule threshold for the number of required ratings can be implemented). In a follow-up we would like to explore this frontier of number of movie ratings vs. prediction accuracy. From this data, a business may want to employ multiple models for light-users and heavy-users of the platform using the number of ratings as a proxy.\n",
    "\n",
    "#### Online vs. Offline\n",
    "\n",
    "TODO: Update for yelp project\n",
    "\n",
    "We would recommend matrix factorization for an online method as the results shows it provides good accuracy as data grows and its latent factor representation is more scalable in runtime (based on our observations of less than linear growth from 50k to 150k datapoints) and memory (unable to run past 150k datapoints using a high-end consumer laptop). Hosting the entire growing dataset to provide a neighborhood-based recommendation will see rapidly increasing resource demands.\n",
    "\n",
    "\n",
    "#### Method Accuracy\n",
    "\n",
    "TODO: Update for yelp project\n",
    "\n",
    "A method that provides a < 20%  precision of a top 5 recommendation approach (1/5 = 20%) may be considered insufficient for the business to release as it is not able to recommend a single movie an user will watch reliably. Thus the business can establish a minimal accuracy threshold as a business rule for real-world implementation. In our experiment, the popularity based baseline would not meet this hurdle while both collaborative filtering method would pass.\n",
    "\n",
    "\n",
    "#### Recommendation Diversity\n",
    "\n",
    "TODO: Update for yelp project\n",
    "\n",
    "Recommendation diversity, as measured by our coverage metric, can be a notable consideration. A business like Netflix could favor a high level of coverage across their catalogue to limit their showings of a smaller selection of blockbuster movies if they a higher pay-per-view licensing fee to content distributors. If they could recommend more indie or niche movies while providing high levels of user engagement then they could save on licensing costs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions and Takeaways\n",
    "\n",
    "TODO: Update for yelp project\n",
    "\n",
    "We have shown that both memory-based and model-based collaborative filtering approaches are effective at providing movie recommendations better in terms of accuracy and diversity than a baseline popularity-based approach. We provided practical implementation considerations for businesses wishing to adopt one of our approaches. We have developed a Spark ML implementation of the collaborative filtering methods that takes advantage of a distributed computing framework for easier resource scaling. The researchers would like to continue to investigate the impact of the number of user ratings on accuracy, effects of even larger datasets and taking into consideration the types of movie genres or release years the user has rated as a input to improve recommendations.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "1: https://towardsdatascience.com/precision-vs-recall-386cf9f89488\n",
    "\n",
    "2: https://surprise.readthedocs.io/en/stable/index.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
