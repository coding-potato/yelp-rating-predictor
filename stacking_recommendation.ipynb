{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble model\n",
    "\n",
    "### Basic Ensemble Techniques\n",
    "The idea of ensemble model is to stack a set of base recommendation models and use the weighted sum of the predictions as the new prediction which will  remove the flaws in individual implementation.\n",
    "- Averaging\n",
    "- Weighted Average (Train weights with linear regression and ElasticNet regression)\n",
    "\n",
    "#### Steps:\n",
    "1. Tune the hyperparameter of base models including:\n",
    "    - Neighborhood based model\n",
    "    - SVD\n",
    "    - baselineonly\n",
    "    - co-colustering\n",
    "2. Train base models using the tuned hyperparameters\n",
    "3. Run regression to learn the weights or simply user average\n",
    "4. Stack models together with weights (average or trained weights)\n",
    "\n",
    "#### Results:\n",
    "\n",
    "##### Accuracy matrix: RMSE\n",
    "\n",
    "Base Models: 1.13 - 1.33\n",
    "\n",
    "Ensemble with average weights: 1.32\n",
    "\n",
    "Ensemble with weights learned from linear regression: 1.32\n",
    "\n",
    "Ensemble with weights learned from ElasticNet: 1.39\n",
    "\n",
    "##### Accuracy matrix: MAE\n",
    "\n",
    "Base Models: 0.9 - 1\n",
    "\n",
    "Ensemble with average weights: 1.05\n",
    "\n",
    "Ensemble with weights learned from linear regression: 1.03\n",
    "\n",
    "Ensemble with weights learned from ElasticNet: 1.11\n",
    "\n",
    "\n",
    "### Advanced Ensemble Techniques\n",
    "- Stacking\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from source.utils import train_test_split_feature\n",
    "from surprise import Reader, Dataset\n",
    "from surprise import BaselineOnly, SVD, KNNBasic\n",
    "from surprise.prediction_algorithms.co_clustering import CoClustering\n",
    "from surprise.model_selection import cross_validate\n",
    "from surprise.model_selection import GridSearchCV\n",
    "from surprise import accuracy\n",
    "from surprise.model_selection import split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = pd.read_csv(\"data/feature.csv\")\n",
    "cols = [\n",
    "        \"user_id\",\n",
    "        \"business_id\",\n",
    "        \"review_stars\",\n",
    "        \"review_date\"\n",
    "        ]\n",
    "selected_feature = feature[cols]\n",
    "train_set, test_set = train_test_split_feature(selected_feature.copy())\n",
    "full_set = selected_feature[[\"user_id\",'business_id',\"review_stars\"]]\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "trainset = Dataset.load_from_df(train_set[['user_id', 'business_id', 'review_stars']], reader)\n",
    "testset = Dataset.load_from_df(test_set[['user_id', 'business_id', 'review_stars']], reader)\n",
    "fullset = Dataset.load_from_df(full_set[['user_id', 'business_id', 'review_stars']], reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "1.2732091440616835\n",
      "{'bsl_options': {'method': 'als', 'n_epochs': 25, 'reg_u': 5, 'reg_i': 3}}\n"
     ]
    }
   ],
   "source": [
    "# 1. find the best hyperparameters for BaselineOnly\n",
    "param_grid = {'bsl_options': {'method': ['als','sgd'],\n",
    "                              'n_epochs': [10, 25], \n",
    "                              'reg_u': [3, 5],\n",
    "                              'reg_i': [3, 5]}\n",
    "             }\n",
    "grid_search = GridSearchCV(BaselineOnly, param_grid, measures=['rmse'], cv=3)\n",
    "grid_search.fit(data)\n",
    "print(grid_search.best_score['rmse'])\n",
    "print(grid_search.best_params['rmse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2783104771201215\n",
      "{'n_epochs': 25, 'lr_all': 0.01, 'reg_all': 0.2}\n"
     ]
    }
   ],
   "source": [
    "# 2. find the best hyperparameters for SVD\n",
    "param_grid = {'n_epochs': [25, 40], 'lr_all': [0.01, 0.02],\n",
    "              'reg_all': [0.2]}\n",
    "grid_search = GridSearchCV(SVD, param_grid, measures=['rmse'], cv=3)\n",
    "grid_search.fit(data)\n",
    "print(grid_search.best_score['rmse'])\n",
    "print(grid_search.best_params['rmse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4121145162238307\n",
      "{'n_epochs': 3, 'n_cltr_u': 3, 'n_cltr_i': 3}\n"
     ]
    }
   ],
   "source": [
    "# 3. find the best hyperparameters for co-clustering\n",
    "param_grid = {'n_epochs': [3, 5], 'n_cltr_u': [3, 5],\n",
    "              'n_cltr_i': [3, 5]}\n",
    "grid_search = GridSearchCV(CoClustering, param_grid, measures=['rmse'], cv=3)\n",
    "grid_search.fit(data)\n",
    "print(grid_search.best_score['rmse'])\n",
    "print(grid_search.best_params['rmse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from source.stacking_recommender import StackingModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************** Start retraining models ******************\n",
      "*************** Retraining: baselineonly *****************\n",
      "Estimating biases using als...\n",
      "RMSE: 1.1351\n",
      "MAE:  0.8981\n",
      "Estimating biases using als...\n",
      "RMSE: 1.1366\n",
      "MAE:  0.8989\n",
      "*************** Retraining: svd *****************\n",
      "RMSE: 1.1400\n",
      "MAE:  0.9022\n",
      "RMSE: 1.1395\n",
      "MAE:  0.9019\n",
      "*************** Retraining: coClustering *****************\n",
      "RMSE: 1.2573\n",
      "MAE:  0.9406\n",
      "RMSE: 1.2625\n",
      "MAE:  0.9440\n",
      "*************** Retraining: knn *****************\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.3274\n",
      "MAE:  0.9958\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.3270\n",
      "MAE:  0.9959\n",
      "******************** Models retrained *********************\n",
      "*** Starting tuning hyperparameter for stacking weights ***\n",
      "RMSE: 0.9818\n",
      "The RMSE for train is 0.9818120839642133\n",
      "MAE:  0.7275\n",
      "The MAE for train is 0.7274999461539339\n",
      "RMSE: 1.3159\n",
      "The RMSE for train is 1.3158572499547387\n",
      "MAE:  1.0278\n",
      "The MAE for train is 1.027755136695534\n"
     ]
    }
   ],
   "source": [
    "# Stacking Model with weights which trained by Linear regression w.o. regularization\n",
    "stacking_model_LR = StackingModel(fullset)\n",
    "stacking_model_LR.fit(trainset, retrain=True, retrain_split_num=2)\n",
    "stacking_model_LR_pred_train = stacking_model_LR.test(trainset.build_full_trainset().build_testset())\n",
    "print(f'The RMSE for train is {accuracy.rmse(stacking_model_LR_pred_train)}')\n",
    "print(f'The MAE for train is {accuracy.mae(stacking_model_LR_pred_train)}')\n",
    "stacking_model_LR_pred = stacking_model_LR.test(testset.build_full_trainset().build_testset())\n",
    "print(f'The RMSE for train is {accuracy.rmse(stacking_model_LR_pred)}')\n",
    "print(f'The MAE for train is {accuracy.mae(stacking_model_LR_pred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************** Start retraining models ******************\n",
      "*************** Retraining: baselineonly *****************\n",
      "Estimating biases using als...\n",
      "RMSE: 1.1362\n",
      "MAE:  0.8981\n",
      "Estimating biases using als...\n",
      "RMSE: 1.1359\n",
      "MAE:  0.8990\n",
      "*************** Retraining: svd *****************\n",
      "RMSE: 1.1395\n",
      "MAE:  0.9019\n",
      "RMSE: 1.1401\n",
      "MAE:  0.9020\n",
      "*************** Retraining: coClustering *****************\n",
      "RMSE: 1.2601\n",
      "MAE:  0.9421\n",
      "RMSE: 1.2556\n",
      "MAE:  0.9388\n",
      "*************** Retraining: knn *****************\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.3263\n",
      "MAE:  0.9948\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.3272\n",
      "MAE:  0.9951\n",
      "******************** Models retrained *********************\n",
      "*** Starting tuning hyperparameter for stacking weights ***\n",
      "RMSE: 1.2209\n",
      "The RMSE for train is 1.2208682531140647\n",
      "MAE:  0.9279\n",
      "The MAE for train is 0.9279317916043214\n",
      "RMSE: 1.3932\n",
      "The RMSE for train is 1.3932336243705696\n",
      "MAE:  1.1132\n",
      "The MAE for train is 1.1132110714892172\n"
     ]
    }
   ],
   "source": [
    "# Stacking Model with weights which trained by ElasticNet\n",
    "stacking_model_EN = StackingModel(fullset)\n",
    "stacking_model_EN.fit(trainset, ensemble_method=\"LR:ElasticNet\", retrain=True, retrain_split_num=2)\n",
    "stacking_model_EN_pred_train = stacking_model_EN.test(trainset.build_full_trainset().build_testset())\n",
    "print(f'The RMSE for train is {accuracy.rmse(stacking_model_EN_pred_train)}')\n",
    "print(f'The MAE for train is {accuracy.mae(stacking_model_EN_pred_train)}')\n",
    "stacking_model_EN_pred = stacking_model_EN.test(testset.build_full_trainset().build_testset())\n",
    "print(f'The RMSE for train is {accuracy.rmse(stacking_model_EN_pred)}')\n",
    "print(f'The MAE for train is {accuracy.mae(stacking_model_EN_pred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************** Start retraining models ******************\n",
      "*************** Retraining: baselineonly *****************\n",
      "Estimating biases using als...\n",
      "RMSE: 1.1356\n",
      "MAE:  0.8985\n",
      "Estimating biases using als...\n",
      "RMSE: 1.1368\n",
      "MAE:  0.8989\n",
      "*************** Retraining: svd *****************\n",
      "RMSE: 1.1396\n",
      "MAE:  0.9018\n",
      "RMSE: 1.1397\n",
      "MAE:  0.9020\n",
      "*************** Retraining: coClustering *****************\n",
      "RMSE: 1.2547\n",
      "MAE:  0.9387\n",
      "RMSE: 1.2595\n",
      "MAE:  0.9417\n",
      "*************** Retraining: knn *****************\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.3265\n",
      "MAE:  0.9943\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.3256\n",
      "MAE:  0.9947\n",
      "******************** Models retrained *********************\n",
      "RMSE: 1.0233\n",
      "The RMSE for train is 1.0232740640563724\n",
      "MAE:  0.7885\n",
      "The MAE for train is 0.7885227426778852\n",
      "RMSE: 1.3172\n",
      "The RMSE for train is 1.3171515246557777\n",
      "MAE:  1.0517\n",
      "The MAE for train is 1.0516577517405332\n"
     ]
    }
   ],
   "source": [
    "# Stacking Model with average weights\n",
    "stacking_model_AVG = StackingModel(fullset)\n",
    "stacking_model_AVG.fit(trainset, ensemble_method=\"Average\", retrain=True, retrain_split_num=2)\n",
    "stacking_model_AVG_pred_train = stacking_model_AVG.test(trainset.build_full_trainset().build_testset())\n",
    "print(f'The RMSE for train is {accuracy.rmse(stacking_model_AVG_pred_train)}')\n",
    "print(f'The MAE for train is {accuracy.mae(stacking_model_AVG_pred_train)}')\n",
    "stacking_model_AVG_pred = stacking_model_AVG.test(testset.build_full_trainset().build_testset())\n",
    "print(f'The RMSE for train is {accuracy.rmse(stacking_model_AVG_pred)}')\n",
    "print(f'The MAE for train is {accuracy.mae(stacking_model_AVG_pred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
