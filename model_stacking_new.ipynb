{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we have 6685900 ratings\n",
      "the number of unique users we have is: 1637138\n",
      "the number of unique business we have is: 192606\n",
      "The median user rated 1 books.\n",
      "The max rating is: 5 the min rating is: 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>business_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hG7b0MtEbXx5QzbzE6C_VA</td>\n",
       "      <td>ujmEBvifdJM6h6RLv4wQIg</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2013-05-07 04:34:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>yXQM5uF2jS6es16SJzNHfg</td>\n",
       "      <td>NZnhc2sEQy3RmzKTZnqtwQ</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2017-01-14 21:30:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>n6-Gk65cPZL6Uz8qRm3NYw</td>\n",
       "      <td>WTqjgwHlXbSFevF32_DJVw</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2016-11-09 20:09:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dacAIZ6fTM6mqwW5uxkskg</td>\n",
       "      <td>ikCg8xy5JIg_NGPx-MSIDA</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2018-01-09 20:56:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ssoyf2_x0EQMed6fgHeMyQ</td>\n",
       "      <td>b1b1eb3uo-w561D0ZfCEiQ</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2018-01-30 23:07:38</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  user_id             business_id  rating                 date\n",
       "0  hG7b0MtEbXx5QzbzE6C_VA  ujmEBvifdJM6h6RLv4wQIg     1.0  2013-05-07 04:34:36\n",
       "1  yXQM5uF2jS6es16SJzNHfg  NZnhc2sEQy3RmzKTZnqtwQ     5.0  2017-01-14 21:30:33\n",
       "2  n6-Gk65cPZL6Uz8qRm3NYw  WTqjgwHlXbSFevF32_DJVw     5.0  2016-11-09 20:09:03\n",
       "3  dacAIZ6fTM6mqwW5uxkskg  ikCg8xy5JIg_NGPx-MSIDA     5.0  2018-01-09 20:56:38\n",
       "4  ssoyf2_x0EQMed6fgHeMyQ  b1b1eb3uo-w561D0ZfCEiQ     1.0  2018-01-30 23:07:38"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('we have',ratings.shape[0], 'ratings')\n",
    "print('the number of unique users we have is:', len(ratings.user_id.unique()))\n",
    "print('the number of unique business we have is:', len(ratings.business_id.unique()))\n",
    "print(\"The median user rated %d books.\"%ratings.user_id.value_counts().median())\n",
    "print('The max rating is: %d'%ratings.rating.max(),\"the min rating is: %d\"%ratings.rating.min())\n",
    "ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6685900/6685900 [00:52<00:00, 127773.63it/s]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from surprise import Reader, Dataset\n",
    "from surprise.model_selection import train_test_split\n",
    "from surprise import NormalPredictor\n",
    "from surprise import BaselineOnly, SVD, KNNBasic\n",
    "from surprise.prediction_algorithms.co_clustering import CoClustering\n",
    "from surprise.model_selection import cross_validate\n",
    "from surprise.model_selection import GridSearchCV\n",
    "from surprise import accuracy\n",
    "from surprise.model_selection import split\n",
    "\n",
    "\n",
    "DATA_FOLDER = 'yelp_dataset'\n",
    "review_datafile = os.path.join(DATA_FOLDER,\"review.json\")\n",
    "line_count = len(open(review_datafile).readlines())\n",
    "user_ids, business_ids, stars, dates = [], [], [], []\n",
    "with open(review_datafile) as f:\n",
    "    for line in tqdm(f, total=line_count):\n",
    "        blob = json.loads(line)\n",
    "        user_ids += [blob[\"user_id\"]]\n",
    "        business_ids += [blob[\"business_id\"]]\n",
    "        stars += [blob[\"stars\"]]\n",
    "        dates += [blob[\"date\"]]\n",
    "ratings = pd.DataFrame(\n",
    "   {\"user_id\": user_ids, \"business_id\": business_ids, \"rating\": stars, \"date\": dates}\n",
    ")\n",
    "user_counts = ratings[\"user_id\"].value_counts()\n",
    "active_users = user_counts.loc[user_counts >= 5].index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = Reader(rating_scale=(1, 5))\n",
    "data = Dataset.load_from_df(ratings[['user_id', 'business_id', 'rating']], reader)\n",
    "train_set, test_set = train_test_split(data, test_size=.2)\n",
    "kSplit = split.KFold(n_splits=2, shuffle=True) # split data into folds. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "1.2732091440616835\n",
      "{'bsl_options': {'method': 'als', 'n_epochs': 25, 'reg_u': 5, 'reg_i': 3}}\n"
     ]
    }
   ],
   "source": [
    "# 1. find the best hyperparameters for BaselineOnly\n",
    "param_grid = {'bsl_options': {'method': ['als','sgd'],\n",
    "                              'n_epochs': [10, 25], \n",
    "                              'reg_u': [3, 5],\n",
    "                              'reg_i': [3, 5]}\n",
    "             }\n",
    "grid_search = GridSearchCV(BaselineOnly, param_grid, measures=['rmse'], cv=3)\n",
    "grid_search.fit(data)\n",
    "print(grid_search.best_score['rmse'])\n",
    "print(grid_search.best_params['rmse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2783104771201215\n",
      "{'n_epochs': 25, 'lr_all': 0.01, 'reg_all': 0.2}\n"
     ]
    }
   ],
   "source": [
    "# 2. find the best hyperparameters for SVD\n",
    "param_grid = {'n_epochs': [25, 40], 'lr_all': [0.01, 0.02],\n",
    "              'reg_all': [0.2]}\n",
    "grid_search = GridSearchCV(SVD, param_grid, measures=['rmse'], cv=3)\n",
    "grid_search.fit(data)\n",
    "print(grid_search.best_score['rmse'])\n",
    "print(grid_search.best_params['rmse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4121145162238307\n",
      "{'n_epochs': 3, 'n_cltr_u': 3, 'n_cltr_i': 3}\n"
     ]
    }
   ],
   "source": [
    "# 3. find the best hyperparameters for co-clustering\n",
    "param_grid = {'n_epochs': [3, 5], 'n_cltr_u': [3, 5],\n",
    "              'n_cltr_i': [3, 5]}\n",
    "grid_search = GridSearchCV(CoClustering, param_grid, measures=['rmse'], cv=3)\n",
    "grid_search.fit(data)\n",
    "print(grid_search.best_score['rmse'])\n",
    "print(grid_search.best_params['rmse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmseBaseline = []\n",
    "rmseSVD = []\n",
    "rmseCo = []\n",
    "rmseSlope = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "RMSE: 1.2835\n",
      "Estimating biases using als...\n",
      "RMSE: 1.2838\n"
     ]
    }
   ],
   "source": [
    "baselineOnly = BaselineOnly(bsl_options={'method': 'als',\n",
    "                                   'n_epochs': 25,\n",
    "                                   'reg_u': 5,\n",
    "                                   'reg_i': 3\n",
    "                                   })\n",
    "for trainset, testset in kSplit.split(data): #iterate through the folds.\n",
    "    baselineOnly.fit(trainset)\n",
    "    predictionsBaselineOnly = baselineOnly.test(testset)\n",
    "    rmseBaseline.append(accuracy.rmse(predictionsBaselineOnly,verbose=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1.2896\n",
      "RMSE: 1.2893\n"
     ]
    }
   ],
   "source": [
    "svd = SVD(lr_all=0.01,n_epochs=25,reg_all=0.2)\n",
    "for trainset, testset in kSplit.split(data): #iterate through the folds.\n",
    "    svd.fit(trainset)\n",
    "    predictionsSVD = svd.test(testset)\n",
    "    rmseSVD.append(accuracy.rmse(predictionsSVD,verbose=True))#get root means squared error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1.4325\n",
      "RMSE: 1.4332\n"
     ]
    }
   ],
   "source": [
    "coClus = CoClustering(n_epochs=3, n_cltr_u=3, n_cltr_i=3) \n",
    "for trainset, testset in kSplit.split(data): #iterate through the folds.\n",
    "    coClus.fit(trainset)\n",
    "    predictionsCoClus = coClus.test(testset)\n",
    "    rmseCo.append(accuracy.rmse(predictionsCoClus,verbose=True))#get root means squared error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from surprise.prediction_algorithms.slope_one import SlopeOne\n",
    "# slopeOne = SlopeOne()\n",
    "# for trainset, testset in kSplit.split(data): #iterate through the folds.\n",
    "#     slopeOne.fit(trainset)\n",
    "#     predictionsSlope = slopeOne.test(testset)\n",
    "#     rmseSlope.append(accuracy.rmse(predictionsSlope,verbose=True))#get root means squared error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import AlgoBase\n",
    "import numpy as np\n",
    "class HybridFacto(AlgoBase):\n",
    "    def __init__(self,epochs, learning_rate,num_models):\n",
    "        self.alpha = np.array([1.0/num_models]*num_models)\n",
    "        self.epochs = epochs\n",
    "        self.learning_rate = learning_rate\n",
    "    def fit(self,holdout):\n",
    "        holdout = holdout.build_full_trainset().build_testset()\n",
    "        for epoch in range(self.epochs):\n",
    "            predictions = np.array([baselineOnly.test(holdout),svd.test(holdout),coClus.test(holdout)])\n",
    "            maeGradient = [accuracy.rmse(prediction,verbose=True) for prediction in predictions]\n",
    "            newalpha = self.alpha - learning_rate * maeGradient  \n",
    "            #convergence check:\n",
    "            if newalpha - self.alpha < 0.001:\n",
    "                break\n",
    "            self.alpha = newalpha\n",
    "    def estimate(self,u,i):\n",
    "        if not (self.trainset.knows_user(u) and self.trainset.knows_item(i)):\n",
    "            raise PredictionImpossible('User and/or item is unkown.')\n",
    "        algoResults = np.array([collabKNN.predict(u,i),funkSVD.predict(u,i),coClus.predict(u,i)])\n",
    "        return np.sum(np.dot(self.alpha,algoResults))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-9c9b973ccca2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mhybrid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mHybridFacto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlearning_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.05\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_models\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mhybrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mrmseHyb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtrainset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestset\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkSplit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m#iterate through the folds.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mpredhybrid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mHyhybrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-958ed57dfc71>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, holdout)\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbaselineOnly\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mholdout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msvd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mholdout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcoClus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mholdout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m             \u001b[0mmaeGradient\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmae\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mprediction\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m             \u001b[0mnewalpha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malpha\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlearning_rate\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmaeGradient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0;31m#convergence check:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-958ed57dfc71>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbaselineOnly\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mholdout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msvd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mholdout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcoClus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mholdout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m             \u001b[0mmaeGradient\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmae\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mprediction\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m             \u001b[0mnewalpha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malpha\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlearning_rate\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmaeGradient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0;31m#convergence check:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.8/lib/python3.6/site-packages/surprise/accuracy.py\u001b[0m in \u001b[0;36mmae\u001b[0;34m(predictions, verbose)\u001b[0m\n\u001b[1;32m    112\u001b[0m     \"\"\"\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Prediction list is empty.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    }
   ],
   "source": [
    "hybrid = HybridFacto(epochs = 10,learning_rate = 0.05,num_models = 3)\n",
    "hybrid.fit(data)\n",
    "rmseHyb = []\n",
    "for trainset, testset in kSplit.split(data): #iterate through the folds.\n",
    "    predhybrid = Hyhybrid.test(testset)\n",
    "    rmseHyb.append(accuracy.rmse(predhybrid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "RMSE: 1.2693\n",
      "Estimating biases using als...\n",
      "RMSE: 1.2700\n",
      "Estimating biases using als...\n",
      "RMSE: 1.2693\n",
      "Estimating biases using als...\n",
      "RMSE: 1.2691\n",
      "Estimating biases using als...\n",
      "RMSE: 1.2692\n",
      "Estimating biases using als...\n",
      "RMSE: 1.2697\n",
      "Estimating biases using als...\n",
      "RMSE: 1.2686\n",
      "Estimating biases using als...\n",
      "RMSE: 1.2710\n",
      "Estimating biases using als...\n",
      "RMSE: 1.2702\n",
      "Estimating biases using als...\n",
      "RMSE: 1.2699\n"
     ]
    }
   ],
   "source": [
    "# sim_options = sim_options = {'name': 'cosine',\n",
    "#                'user_based': False  # compute  similarities between items\n",
    "#                }\n",
    "# collabKNN = KNNBasic(k=40,sim_options=sim_options) #try removing sim_options. You'll find memory errors. \n",
    "# collabKNN = KNNBasic(k=40)\n",
    "baseline_als = BaselineOnly(bsl_options={'method': 'als',\n",
    "                                   'n_epochs': 5,\n",
    "                                   'reg_u': 12,\n",
    "                                   'reg_i': 5\n",
    "                                   })\n",
    "rmseKNN = []\n",
    "rmseSVD = []\n",
    "rmseCo = []\n",
    "rmseSlope = []\n",
    "for trainset, testset in kSplit.split(data): #iterate through the folds.\n",
    "    baseline_als.fit(trainset)\n",
    "    predictionsKNN = baseline_als.test(testset)\n",
    "    rmseKNN.append(accuracy.rmse(predictionsKNN,verbose=True))#get root means squared error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1.3904\n",
      "RMSE: 1.3928\n",
      "RMSE: 1.3947\n",
      "RMSE: 1.3913\n",
      "RMSE: 1.3932\n",
      "RMSE: 1.3920\n",
      "RMSE: 1.3900\n",
      "RMSE: 1.3970\n",
      "RMSE: 1.3960\n",
      "RMSE: 1.3894\n"
     ]
    }
   ],
   "source": [
    "from surprise.prediction_algorithms.co_clustering import CoClustering\n",
    "coClus = CoClustering(n_cltr_u=4,n_cltr_i=4,n_epochs=25) \n",
    "for trainset, testset in kSplit.split(data): #iterate through the folds.\n",
    "    coClus.fit(trainset)\n",
    "    predictionsCoClus = coClus.test(testset)\n",
    "    rmseCo.append(accuracy.rmse(predictionsCoClus,verbose=True))#get root means squared error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algos = {'Baseline_ALS': [BaselineOnly(bsl_options={'method': 'als',\n",
    "                                   'n_epochs': 5,\n",
    "                                   'reg_u': 12,\n",
    "                                   'reg_i': 5\n",
    "                                   }),]\n",
    "        }\n",
    "\n",
    "\n",
    "# algos = {'Baseline_ALS': BaselineOnly(bsl_options={'method': 'als',\n",
    "#                                    'n_epochs': 5,\n",
    "#                                    'reg_u': 12,\n",
    "#                                    'reg_i': 5\n",
    "#                                    }),\n",
    "#          'Baseline_SGD': BaselineOnly(bsl_options={'method': 'sgd',\n",
    "#                                    'learning_rate': .00005,\n",
    "#                                    }),\n",
    "#          'SVD': SVD(),\n",
    "#          'NeighborhoodBased_User': KNNBasic(sim_options={'name': 'cosine',\n",
    "#                                'user_based': True\n",
    "#                                })\n",
    "#         }\n",
    "algo_list = {}\n",
    "for algo_name in algos:\n",
    "    print (f\"Algo is: {algo_name}\")\n",
    "    algo = algos[algo_name]\n",
    "    algo.fit(trainset)\n",
    "    predictions = algo.test(testset)\n",
    "    algo_accuracy = accuracy.rmse(predictions)\n",
    "    algos[algo_name][1] = algo_accuracy\n",
    "    print (algo_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
